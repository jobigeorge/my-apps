---
layout:     post
title:      "PCs and web2.0 : Part 2 PCs the perfect Interaction Engines"
subtitle:   ""
description: ""
excerpt: ""
date:       2006-11-05 11:37:00
author:     " Jobi George"
image:     "static/img/grey-transparent.jpg"
published: true
showtoc: false 
tags:
    - Strategy
    - Ecosystem
    - Business
URL: "/2006/11/05/personal-computer-part2/"
categories: [ Business ]
---
[Last week](/2006/10/19/personal-computers-part1) I talked about how the PCs existing role is being threatened by the evolving push towards services based applications. There is a widespread fear that web2.0 and SaaS will finally kill the thick Moore's law driven PC and we all will be either working of dumb terminals or the cell phone size devices that will run all our applications. !["Move towards Thick Compute Thin State"](/img/blogimg/20061105-thickthin.jpg)


Certainly skeptics and realists are arriving and last weeks blog by [John Milan](http://intelligantt.blogspot.com/) talked about how [Google's desktop based application strategy](http://www.readwriteweb.com/archives/elephants_and_evolution.php) is evolving. I believe that PC type high end compute devices will still be around but certainly with a new defined role of providing stateless and cheap raw computes.

Going forward PC will take on more the role of local storage/caching/execution device. It is already happening, PC in home is already the synching & charging station, music mixer & browsing device, [Sam Ruby](http://intertwingly.net/slides/2006/npuc/) from IBM has a great presentation on the topic. While in enterprise PCs are quickly becoming thin state compute player with role based applications/kiosks becoming commonplace.


**Thick Compute Thin State**

 The end user client nodes though loosing lot of application level computes to the cloud are certainly gaining lot of interaction level computes. Be it the browser based application that uses lot of rich [AJAX](http://www.adaptivepath.com/publications/essays/archives/000385.php) code such as Zimbra or the role based deployments of enterprise applications. I remember somebody mentioning me that the [Zimbra](http://www.zimbra.com/) demos looked awful till Intel Core2Duo showed up, especially thru in the case of Apple Macs. Certainly with loosely coupled applications and mashups happening at the last mile the interaction level computes are bound to rise at the point of interactions. Added to that increasing desire of flexibility and agility prompts development at higher level abstracted languages, pushing performance as a back burner and certainly consuming MIPS very inefficiently.

The tipping of broadband adoption beyond 50%, the availability of cheap hardware and open source stacks have finally brought in the ability to break out from the limitations of client server model. Applications are not going to be written in the old ways and that means applications can finally be experienced differently. Application streaming vendors and role based deployment stacks are bridging the gap for existing client server applications in the enterprise space while in the consumer space everybody seems to be rallying behind web2.0


**PC going from Multi Applications to Multi Player**

 It was while working on the [PDS](http://www.usenix.org/publications/library/proceedings/vee05/full_papers/p175-alpern.pdf) project at [IBM T.J Watson lab](http://www.watson.ibm.com/index.shtml) that we coined the term “Application Player” for the first time. Applications that can be experienced as a stream similar to watching a MPEG file or internet radio stream. The real implication was that now one could treat compiled applications and play it like any media using a S/W player. !["Move towards Thick Compute Thin State"](/img/blogimg/20061105-pcclient.jpg)
 
 This meant that the composition and packaging of application is totally independent of the way applications are run. After all we always knew that runtime characteristics of an application is totally different from the design time and compose time characteristics, just didn't know how to manage it differently. By being able to separate these attributes it is now possible to pull in some of the composition and assembly aspect of application into the cloud, while also make the edge a better runtime stateless player. I think Microsoft is also thinking in the same line and the increased focus on declarative languages like XUL, XAML, FLEX makes it easier to reach there.

This is the biggest opportunity for PC. PCs can now become the perfect form of **interaction engine**. Finally the glue that stuck OS and applications to PCs are loosening and PCs could be redefined into a platform for interaction. Things like device driver models that have become a nightmare inside the Operating system could be pulled back to the hardware and used to putting up a softer face. It is time for us to look beyond the keyboard and mouse interfaces and provide an interaction based programming interface and tools that can be applied to things such as multi-touch, voice, conversational systems, 360° camera. PC's or PC type devices will start becoming the enabler of the [local infoclound](http://vanderwal.typepad.com/personal_infocloud/). And with the onset of virtualization technology in chips and open source VMMs now we have the basic building blocks to build this.

I am excited by the opportunity and believe this is just the beginning. The whole service orientation of applications and ability to experience the Application Anywhere Anytime is finally going to bring the information to fingertips and is heralding in new era for computer science.

PC is marching towards becoming the perfect “Interaction Engine” and who knows how many unintended uses will emerge. Here is one that is using exisiting PC hardware to predict [Tsunami's using vibrations on your hard disk](http://www.ninsight.at/tsunami/)



##### Original Post

* Originally posted at [ Blogspot ]( http://jobig.blogspot.com/2006/11/pcs-and-web20-part-2-pcs-perfect.html) on {{< param date >}}


